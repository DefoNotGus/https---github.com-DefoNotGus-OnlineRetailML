{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Big data analitics**\n",
    "\n",
    "**Assesment project**\n",
    "\n",
    "Online retails database.\n",
    "This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.\n",
    "\n",
    "The aim of this project is to analyze, visualize and study our retail dataset previously mentioned which has been imported from *https://archive.ics.uci.edu/dataset/352/online+retail*.\n",
    "\n",
    "This dataset was chosen because Machine Learning has had a masive impact in the online retail world. So I wanted my project to be orientated to analyzing a retail dataset in order to analize how Machine Learning can benefit companies to understand patterns among their customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset:** Online Retail\n",
    "https://archive.ics.uci.edu/dataset/352/online+retail\n",
    "\n",
    "Features: 8\n",
    "\n",
    "Instances:541909\n",
    "\n",
    "\n",
    "Donated: on 2015\n",
    "\n",
    "Downloaded: 04/10/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Peer-reviewed**\n",
    "\n",
    "I used for my peer-review reference one relevant paper called \"The role of machine learning analytics and metrics in retailing research\" it is aim to explain how machine learning has benefit the retail industry for customer and sales resarching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aim**\n",
    "\n",
    "The aim of the algorithm of my machine learning is two display in a clear way the relevant data to the user and to make  a country prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "The Dataset used contains information about online sells from UK-retailers. The aim is to build a productive model to predict what is the nationality of potential customers. In order for companies to know what is their strongest markets.\n",
    "\n",
    "Peer-reviewed Paper: *https://www.sciencedirect.com/science/article/pii/S0022435920300932#abs0010*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing required libraries**\n",
    "\n",
    "Firstly we will Import our required libraries and import our database in CSV format using pandas. Seaborn and matplotlib.pyplot is used for displaying visually data and we will use  sklearn for applying decision tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required variables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "df = pd.read_csv('Online Retail.csv')\n",
    "df.head(10) #or simply df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can confirm that our database works we will do some exploration on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size or shape of our dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The dataset has {df.shape[0]} rows and {df.shape[1]} columns')\n",
    "originalRow = df.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has 541909 records or instances and 8 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will drop empty values records. if there is any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape[0])\n",
    "newRow = originalRow  - df.shape[0] \n",
    "print(f'The dataset has {df.shape[0]} rows and {newRow} has been dropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our total usable dataset has 406829 rows and 8 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the dataset.**\n",
    "\n",
    "Here we display the Country feature to display for the retailers non-uk sales vs uk sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Country'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uksalescount = df.groupby('Country').size()['United Kingdom']\n",
    "UkporcentSales = (Uksalescount * 100)/df.shape[0]\n",
    "print(f\"UK represnts {UkporcentSales}% with {Uksalescount} sales \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above we can see that UK represets 88.9% of the total sales of the company. Which will make it more challenging at the time of predicting Countries like Saudi Arabia and Bahrain which don't buy a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = (df['Country'].unique())\n",
    "print(countries)\n",
    "\n",
    "print(f'\\n We have {len(countries)} different Countries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown before, we have in our dataset 37 different coutries which means 36 countries represent just over the 10% of our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use seaborn python library for displaying a graph with a relationship between the amount of sales per country. However since our dataset file has 541909 records, I will use the first  10 000 records instead for the program to run quicker. this sample will be use for training my machine learning algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y='Country', data=df.head(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "United Kingdom data creates an imbalance within our dataset. This could become a problem in our algorithm because the accuraccy could be really high but not because of the efficiency of our algorithm. Which means our accuracy is not really reflecting the efficiency of our algorithm.\n",
    "\n",
    "In order to solve this problem I will proceed to take a random *20%* of the records of purchases made on United Kingdom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inbalance**\n",
    "\n",
    "Now we will make a month and day subfeature for flexibility purpuses when displaying our graphs in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows where 'Country' is 'UK'\n",
    "uk_rows = df[df['Country'] == 'United Kingdom']\n",
    "\n",
    "# Calculate the number of rows to drop (80% of UK rows)\n",
    "rows_to_drop = int(0.80 * len(uk_rows)) #just an interger\n",
    "print(f\" from United Kingdom's records we will delete '{rows_to_drop} records.\")\n",
    "\n",
    "# Get the index values of rows to drop\n",
    "indexes_to_drop = uk_rows.sample(rows_to_drop).index\n",
    "\n",
    "# Drop rows by index values\n",
    "df = df.drop(indexes_to_drop)\n",
    "\n",
    "# Now 'df' contains the dataset with 80% of the 'UK' rows dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now we analyze our dataset after balancing it* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n After the balanced, We have {len(countries)} different Countries')\n",
    "\n",
    "print(df['Country'].value_counts())\n",
    "\n",
    "Uksalescount = df.groupby('Country').size()['United Kingdom']\n",
    "UkporcentSales = (Uksalescount * 100)/df.shape[0]\n",
    "print(f\"UK represnts {UkporcentSales}% with {Uksalescount} sales \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y='Country', data=df.head(10000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df['Month'] = df['InvoiceDate'].dt.month \n",
    "df['Day'] = df['InvoiceDate'].dt.day \n",
    "\n",
    "df.head(10) #or simply df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing data**\n",
    "\n",
    "We first encode categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['Country'] = label_encoder.fit_transform(df['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define X and y.**\n",
    "\n",
    "Here we will define what features we will use in our algorithm and what feature we want our algorithm to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "features = [  'Quantity', 'UnitPrice', 'CustomerID', 'Month']\n",
    "X = df[features]\n",
    "y = df['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a Decision tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Calculate accuracy\n",
    "dt_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to display predicted vs expected countries\n",
    "results_df = pd.DataFrame({'Expected': label_encoder.inverse_transform(y_test), 'Predicted': label_encoder.inverse_transform(y_pred)})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter records where 'Expected' is not equal to 'Predicted'\n",
    "mismatched_records = results_df[results_df['Expected'] != results_df['Predicted']]\n",
    "\n",
    "# Display the mismatched records\n",
    "print(mismatched_records)\n",
    "mismatched_records.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "# Display the decision tree rules\n",
    "tree_rules = export_text(clf, feature_names=features)\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process continues, and at each level, the tree makes a decision based on whether the CustomerID is less than or equal to a specific value. Eventually, the tree reaches a leaf node, where a class label is assigned based on the conditions met during the traversal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Althought we had a very high accuracy we want to check if there is room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Solution Improvement***\n",
    "\n",
    "\n",
    "In order to evaluate the efficeincy of our Machine Learning algorithm it would be Ideal to apply a different algorithm and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forrest:**\n",
    "\n",
    "Random Forest is an ensemble learning method that builds multiple decision trees and merges their predictions for robust and accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first apply the algorithm to our train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for Random Forest\n",
    "rf_results_df = pd.DataFrame({'Expected': label_encoder.inverse_transform(y_test), 'Predicted (Random Forest)': label_encoder.inverse_transform(rf_pred)})\n",
    "rf_mismatched_records = rf_results_df[rf_results_df['Expected'] != rf_results_df['Predicted (Random Forest)']]\n",
    "\n",
    "print(\"\\nResults for Random Forest:\")\n",
    "print(rf_results_df)\n",
    "print(\"\\nMismatched Records for Random Forest:\")\n",
    "print(mismatched_records)\n",
    "print(mismatched_records.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracy\n",
    "dt_accuracy = accuracy_score(y_test, y_pred)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(\"\\nAccuracy Comparison:\")\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection**\n",
    "\n",
    "It turn out at the  end of our solution improvement and comparing the Decision Tree and the Random Forrest implementation that the first choice, the Decision Tree, is more accurate than the Random Forrest. Because In some cases, a Decision Tree can be more accurate than a Random Forest when the dataset is small or lacks complexity.\n",
    "\n",
    "Which means for simpler and smaller datasets in the future is better to use simpler algorithms like Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**\n",
    "\n",
    "How to remove rows with specific values in pandas DataFrame (2023) Saturn Cloud Blog. Available at: https://saturncloud.io/blog/how-to-remove-rows-with-specific-values-in-pandas-dataframe/#:~:text=Another%20method%20to%20remove%20rows,value%20we%20want%20to%20remove. (Accessed: 07 December 2023). \n",
    "Online retail (no date) UCI Machine Learning Repository. Available at: https://archive.ics.uci.edu/dataset/352/online+retail (Accessed: 07 December 2023). \n",
    "user3334393user3334393&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 111 silver badge11 bronze badge et al. (1960) Linking to a CSS stylesheet, Stack Overflow. Available at: https://stackoverflow.com/questions/23312491/linking-to-a-css-stylesheet (Accessed: 07 December 2023). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
